{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Convert date column to datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Sort values for time series consistency\n",
        "df = df.sort_values(['date', 'country', 'store', 'product'])\n",
        "\n",
        "# Fill missing values using backward fill and then forward fill\n",
        "df['num_sold'].fillna(method='bfill', inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKiAInjJbdAd",
        "outputId": "e65fd98a-f8b5-4bdb-ec59-bf4f34390d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-9350fb3ba864>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['num_sold'].fillna(method='bfill', inplace=True)\n",
            "<ipython-input-1-9350fb3ba864>:19: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['num_sold'].fillna(method='bfill', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())  # Check for NaNs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFcVn8VUbhxf",
        "outputId": "6a5c4a7d-de0f-4b9b-b822-8434710d4505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id          0\n",
            "date        0\n",
            "country     0\n",
            "store       0\n",
            "product     0\n",
            "num_sold    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjA4chSgbVuX",
        "outputId": "89532275-4cda-4a4f-f085-a53445a3b7b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([16, 1, 1])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.0143\n",
            "Epoch 2/20, Loss: 0.0142\n",
            "Epoch 3/20, Loss: 0.0142\n",
            "Epoch 4/20, Loss: 0.0142\n",
            "Epoch 5/20, Loss: 0.0142\n",
            "Epoch 6/20, Loss: 0.0142\n",
            "Epoch 7/20, Loss: 0.0142\n",
            "Epoch 8/20, Loss: 0.0142\n",
            "Epoch 9/20, Loss: 0.0142\n",
            "Epoch 10/20, Loss: 0.0142\n",
            "Epoch 11/20, Loss: 0.0142\n",
            "Epoch 12/20, Loss: 0.0142\n",
            "Epoch 13/20, Loss: 0.0142\n",
            "Epoch 14/20, Loss: 0.0142\n",
            "Epoch 15/20, Loss: 0.0142\n",
            "Epoch 16/20, Loss: 0.0142\n",
            "Epoch 17/20, Loss: 0.0142\n",
            "Epoch 18/20, Loss: 0.0142\n",
            "Epoch 19/20, Loss: 0.0142\n",
            "Epoch 20/20, Loss: 0.0142\n",
            "Mean Squared Error (MSE): 0.0095\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Normalize num_sold using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df['num_sold'] = scaler.fit_transform(df[['num_sold']])\n",
        "\n",
        "# Prepare time series data with a sequence length of 30\n",
        "def create_sequences(data, seq_length=30):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Define dataset class\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Define LSTM Model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, output_size=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])  # Use the last output\n",
        "        return out\n",
        "\n",
        "# Convert num_sold to numpy and create sequences\n",
        "num_sold_values = df['num_sold'].values.reshape(-1, 1)\n",
        "seq_length = 30  # Use past 30 days to predict the 31st day\n",
        "X, y = create_sequences(num_sold_values, seq_length)\n",
        "\n",
        "# Split data into train and test sets (80% train, 20% test)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
        "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LSTMModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the LSTM model\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate model on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "actual_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        test_predictions.extend(y_pred.numpy())\n",
        "        actual_values.extend(y_batch.numpy())\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "test_predictions = np.array(test_predictions).flatten()\n",
        "actual_values = np.array(actual_values).flatten()\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(actual_values, test_predictions)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE\n",
        "#mse = mean_squared_error(test_data.values, test_forecast_values)\n",
        "\n",
        "# Calculate PMSE\n",
        "pmse = (mse / np.mean(actual_values)) * 100\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Percentage Mean Squared Error (PMSE): {pmse:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glrm-cvfggPD",
        "outputId": "f66672f0-1910-45b8-be7e-87a0fc9b7c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.009547565132379532\n",
            "Percentage Mean Squared Error (PMSE): 8.39%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}